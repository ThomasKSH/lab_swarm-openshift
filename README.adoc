:sectanchors:
:toc: macro
:toclevels: 2
:toc-title: Table of Content
:numbered:

= Hands On Lab with Wildfly Swarm, Microservices & OpenShift

toc::[]

# Prerequisites

you will need to install the following on your machine:

- [x] http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html[JDK 1.8]
- [x] https://maven.apache.org/download.cgi[Maven 3.3.6 or higher]
- [x] https://www.virtualbox.org/wiki/Downloads[Virtualbox 5.0 or higher]
- [] https://github.com/minishift/minishift[Minishift 1.0.0.Beta3]
- [] https://github.com/openshift/origin/releases/tag/v1.4.1[OpenShift Client 1.4.1]
- [x] http://developers.redhat.com/products/devstudio/download/?referrer=jbd[JBoss Developer Studio 10 (optional)]

# Installation of Minishift

Minishift is a Go Application which has been created from Minikube project of Kubernetes. It extends the features proposed by the Kubernetes client to package/Deploy
OpenShift within a VM machine. Different hypervisors are supported as Virtualbox, xhyve & VMWare. You can find more information about Minishift like also how to intall it from the project:
https://github.com/minishift/minishift

# Setup OpenShift

We will configure the VM on the machine using Virtualbox as Hypervisor, the version 1.4.1 of OpenShift

[source]
----
minishift start --memory=4000 --vm-driver=virtualbox

Starting local OpenShift instance using 'virtualbox' hypervisor...
Provisioning OpenShift via '/Users/chmoulli/.minishift/cache/oc/v1.4.0-rc1/oc [cluster up --use-existing-config --host-config-dir /var/lib/minishift/openshift.local.config --host-data-dir /var/lib/minishift/hostdata]'
-- Checking OpenShift client ... OK
-- Checking Docker client ... OK
-- Checking Docker version ... OK
-- Checking for existing OpenShift container ...
   Deleted existing OpenShift container
-- Checking for openshift/origin:v1.4.0-rc1 image ... OK
-- Checking Docker daemon configuration ... OK
-- Checking for available ports ... OK
-- Checking type of volume mount ...
   Using Docker shared volumes for OpenShift volumes
-- Creating host directories ... OK
-- Finding server IP ...
   Using 192.168.64.25 as the server IP
-- Starting OpenShift container ...
   Starting OpenShift using container 'origin'
   Waiting for API server to start listening
   OpenShift server started
-- Removing temporary directory ... OK
-- Server Information ...
   OpenShift server started.
   The server is accessible via web console at:
       https://192.168.99.101:8443

   To login as administrator:
       oc login -u system:admin

OR

minishift start --openshift-version=v1.4.0 --deploy-router --memory=4000 --vm-driver=virtualbox
Starting local OpenShift cluster...
Downloading OpenShift v1.4.0-rc1
 65.86 MB / 65.86 MB [============================================================================================================================================================================================================================] 100.00% 0sDownloading OpenShift v1.4.0-rc1 checksums
 0 B / 773 B [---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------]   0.00%
 773 B / 773 B [==================================================================================================================================================================================================================================] 100.00% 0s
oc is now configured to use the cluster.
Run this command to use the cluster:
oc login --username=admin --password=admin

or

oc cluster up --docker-machine=openshift --version=v1.4.1 --create-machine
oc cluster up --docker-machine=openshift --version=v1.4.1
----

Next, we will provide more rights for the admin `default` user in order to let it to access the different projects/namespaces to manage the resources.
This step is only required if you use the new Minishift client (> 1.0.0.Beta2)

[source]
----
oc login https://HOST_IP:8443 -u system:admin
oc adm policy add-cluster-role-to-user cluster-admin admin
oc login -u admin -p admin
oc project default
----

## Useful commands

- Stop/start Minishift

[source]
----
minishift stop
minishift start
----

Optionally we can install the OpenShift templates in order to have some examples like WildFly Server, ....

[source]
----
export currentDir=$(pwd)
cd $TEMP_DIR
git clone https://github.com/openshift/openshift-ansible.git
cd openshift-ansible/roles/openshift_examples/files/examples/latest/
for f in image-streams/image-streams-centos7.json; do cat $f | oc create -n openshift -f -; done
for f in db-templates/*.json; do cat $f | oc create -n openshift -f -; done
for f in quickstart-templates/*.json; do cat $f | oc create -n openshift -f -; done
cd $currentDir
----

# Goals

The goal of this project is to create a Microservices application that we will deploy within a virtualized environment managed by OpenShift.
The project will contain 3 modules; a web static Front end, a backend service exposed by WildFly Swarm & a MySQL database.

Each module will be packaged and deployed as a Docker image in OpenShift. The OpenShift tooling as S2I build will be used for that purpose as the Fabric8 Maven Plaugin.
They both, as Kubernetes/OpneShift clients allows to access the platform in order to issue the commands allowing to build/deploy & run a pod.

The project will be created using a Java IDE "IntelliJ, JBoss Developer Studio" tool while JBoss Forge will help us to design the Java application in order to:
- Create the REST Service
- Modelize the JPA Entity & the model
- Scaffold the AngularJS application

# Create project

We will follow the following steps in order to create the maven projects with the modules. Some prerequisites are required like JBoss Forge.

All in one

[source]
----
mvn archetype:generate -DarchetypeGroupId=org.codehaus.mojo.archetypes -DarchetypeArtifactId=pom-root -DarchetypeVersion=RELEASE -DinteractiveMode=false -DgroupId=org.cdstore -DartifactId=project -Dversion=1.0.0-SNAPSHOT
mv project snowcamp && cd snowcamp

brew install jboss-forge
forge
addon-install --coordinate io.fabric8.forge:devops,2.3.88
addon-install --coordinate org.jboss.forge.addon:wildfly-swarm,2017.1

forge -e "run scripts/cdstore.fsh"

echo # ----------------  Book Store Web Front End [:8081/rest] ---------------
echo # Now we want to create front end swarm service to access CD Catalog Service
mkdir cdstorefrontend
cp scripts/front cdstorefrontend
----

- Create the parent maven project where we will design the Front and the backend modules

[source]
----
mvn archetype:generate -DarchetypeGroupId=org.codehaus.mojo.archetypes -DarchetypeArtifactId=pom-root -DarchetypeVersion=RELEASE -DinteractiveMode=false -DgroupId=org.cdstore -DartifactId=project -Dversion=1.0.0-SNAPSHOT
mv project snowcamp && cd snowcamp

# Setup JBoss Forge & Addons
brew install jboss-forge
forge
addon-install --coordinate io.fabric8.forge:devops,2.3.88
addon-install --coordinate org.jboss.forge.addon:wildfly-swarm,2017.1

forge -e "run scripts/cdstore.fsh"
----

# Add parent project (chech with Geirge how to change artefactId)
project-new --named snowcamp --final-name project --type parent --top-level-package org.cdstore

# create the CD Catalog Service project
# ----------------  CD Catalog Service [:8080/rest] ---------------
project-new --named cdservice --stack JAVA_EE_7

# Define PostgreSQL DB
jpa-setup --jpa-provider hibernate --db-type MYSQL --data-source-name java:jboss/datasources/CatalogDS --persistence-unit-name cdservice-persistence-unit

jpa-new-entity --named Catalog
jpa-new-field --named artist --target-entity org.cdservice.model.Catalog
jpa-new-field --named title --target-entity org.cdservice.model.Catalog
jpa-new-field --named description --length 2000 --target-entity org.cdservice.model.Catalog
jpa-new-field --named price --type java.lang.Float --target-entity org.cdservice.model.Catalog
jpa-new-field --named publicationDate --type java.util.Date --temporalType DATE --target-entity org.cdservice.model.Catalog

scaffold-setup --provider AngularJS
scaffold-generate --provider AngularJS --generate-rest-resources --targets org.cdservice.model.*
wildfly-swarm-setup
wildfly-swarm-detect-fractions --depend --build

cd cdservice
rest-new-cross-origin-resource-sharing-filter
fabric8-setup
cd ..

# ----------------  Book Store Web Front End [:8081/rest] ---------------
# Now we want to create front end swarm service to access CD Catalog Service
project-new --named cdstorefrontend --stack JAVA_EE_7 --type wildfly-swarm --http-port 8081
wildfly-swarm-add-fraction --fractions undertow
mv ../cdservice/src/main/webapp/ src/main/

# Keep empty src/main/webapp/WEB-INF
mkdir ../cdservice/src/main/webapp
mkdir ../cdservice/src/main/webapp/WEB-INF

cd ~~
cd ..
----

# Externalize Front Service

- Create service.json file under webapp folder & define the following key/value

  { "cd-service": "http://localhost:8080/rest/catalogs/" }

- Add a config.js file within the directory scripts containing a $http.get request to access the content
  of the json file & fetch the key `cd-service`. This key will contain the hostname or service name to be accessed

[source]
----
angular.module('cdservice').factory('config', function ($http, $q) {
  var deferred = $q.defer();
  var apiUrl = null;
  $http.get("service.json")
    .success(function (data) {
      console.log("Resource : " + data['cd-service'] + ':CatalogId');
      deferred.resolve(data['cd-service']);
      apiUrl = data['cd-service'];
    })
    .error(function () {
      deferred.reject('could not find service.json ....');
    });

  return {
    promise: deferred.promise,
    getApiUrl: function () {
      return apiUrl;
    }
  };
});
----

- Modify the `scripts/services/CatalogFactory.js` to use the fucntion `config` instead of the hard coded value

[source]
----
  return $resource(config.getApiUrl() + ':CatalogId', { CatalogId: '@id' }, {
----

# Database

- Install the OpenShift MySQL Template

  oc new-app --template=mysql-ephemeral \
      -p MYSQL_USER=mysql \
      -p MYSQL_PASSWORD=mysql \
      -p MYSQL_DATABASE=catalogdb

- Next, check if the Database is up and alive

[source]
----
export pod=$(oc get pod | grep mysql | awk '{print $1}')
oc rsh $pod
mysql -u $MYSQL_USER -p$MYSQL_PASSWORD -h $HOSTNAME $MYSQL_DATABASE

mysql> connect catalogdb;
Connection id:    1628
Current database: catalogdb

mysql> SELECT t.* FROM catalogdb.Catalog t;
+----+--------+---------+
| id | name   | version |
+----+--------+---------+
|  1 | abba   |       0 |
|  2 | acdc   |       0 |
|  3 | boston |       0 |
|  4 | u2     |       0 |
+----+--------+---------+
----

- Insert some records (if the table has been created !)

[source]
----
INSERT INTO Catalog (id, artist, description, price, publicationDate, title) VALUES (1,"ACDC","Australian hard rock band", 15.0, '1980-07-25', "Back in Black");
INSERT INTO Catalog (id, artist, description, price, publicationDate, title) VALUES (2,"Abba","Swedish pop music group", 12.0, '1976-10-11', "Arrival");
INSERT INTO Catalog (id, artist, description, price, publicationDate, title) VALUES (3,"Coldplay","British rock band ", 17.0, '2008-07-12', "Viva la Vida");
INSERT INTO Catalog (id, artist, description, price, publicationDate, title) VALUES (4,"U2","Irish rock band ", 18.0, '1987-03-09', "The Joshua Tree");
INSERT INTO Catalog (id, artist, description, price, publicationDate, title) VALUES (5,"Metallica","Heavy metal band", 15.0, '1991-08-12', "Black");
----

- Forward the traffic from the service to the host using `port-forwarding` command

[source]
----
export pod=$(oc get pod | grep mysql | awk '{print $1}')
oc port-forward $pod 3306:3306
----

# Test project locally

- Open 2 terminal in order to start the front & backend
- cd `cdservice`

  npm install
  export PORT=8081
  export URL=http://localhost:8080/rest/catalogs

  OpenShift URL : "http://cdstorefrontend-snowcamp.192.168.99.101.xip.io/rest/catalogs/"

- cd `cdstorefront`

  mvn wildfly-swarm:run

- Open project within your browser `http://localhost:8081/index.html`

# Deployment on OpenShift

- cd Frontend which is a Node application

  cd cdfrontend
  oc new-project snowcamp
  oc delete dc,svc,route,bc,imagestream cdfrontend
  oc new-build --binary --name=cdfrontend -l app=cdfrontend
  #npm install
  oc start-build cdfrontend --from-dir=. --follow
  oc new-app cdfrontend -l app=cdfrontend
  oc env dc/cdfrontend URL=http://cdservice-snowcamp.192.168.99.101.xip.io/rest/catalogs
  #oc env dc/cdfrontend URL=http://cdservice-snowcamp.172.28.128.4.xip.io/rest/catalogs
  oc env dc/cdfrontend PORT=8080
  oc expose service cdfrontend

- cd backend

  cd cdservice
  mvn clean package
  mvn fabric8:resource fabric8:build -Popenshift
  mvn fabric8:deploy -Popenshift

- All Steps

oc cluster up --docker-machine=openshift --version=v1.4.1 --use-existing-config=true

oc login https://192.168.99.101:8443 -u system:admin
oc adm policy add-cluster-role-to-user cluster-admin admin
oc login -u admin -p admin
oc project default

oc new-project snowcamp
oc new-app --template=mysql-ephemeral -p MYSQL_USER=mysql -p MYSQL_PASSWORD=mysql -p MYSQL_DATABASE=catalogdb
sleep 5

cd cdstorefrontend
oc new-build --binary --name=cdfrontend -l app=cdfrontend
#npm install
oc start-build cdfrontend --from-dir=. --follow
oc new-app cdfrontend -l app=cdfrontend
oc env dc/cdfrontend URL=http://cdservice-snowcamp.192.168.99.101.xip.io/rest/catalogs
#oc env dc/cdfrontend URL=http://cdservice-snowcamp.172.28.128.4.xip.io/rest/catalogs
oc env dc/cdfrontend OS_SUBDOMAIN=192.168.99.101.xip.io
oc env dc/cdfrontend OS_PROJECT=snowcamp
oc env dc/cdfrontend PORT=8080
oc expose service cdfrontend

cd ../cdservice
mvn clean package
mvn fabric8:deploy -Popenshift









